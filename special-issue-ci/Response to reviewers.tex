\documentclass[preprint]{elsarticle}
\biboptions{round, numbers}
\usepackage[latin1]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{color}
%\usepackage{setspace}
\usepackage{url}
\usepackage[english]{babel}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   TITLE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Volunteers in the Clouds: an Architecture for Low Cost and
  Potentially Massive Distributed Evolutionary Computation: Response to Reviewers\' comments}

\noindent
Dear Sirs,\\

We really appreciate the opportunity you have given us for improving
our work. Following the reviewers' requests and suggestions we have
deeply changed the contents, and thus, the quality of the paper. 

We would like to notify the editors that, thanks to changes and
aportations made to this new version of the paper there are two new
coauthors. 

In the next sections you can find these comments and our responses
to every one, along with the changes done.\\ 

\noindent
Yours sincerely,\\
The authors.

\section{Response to Reviewer \#1}

\begin{quote}
The main contribution of this paper is the proposal of a Javascript based distributed system intended to
run evolutionary algorithms according to the volunteer computing scheme. The idea is that user can
contribute to the computation by using only a browser, without needing to install any plugin nor a Java
virtual machine.
The volunteer computing model appeared some years ago and it has been used in many fields. The
model is effective to solve problems demanding high computational capabilities, and at this point is where
this paper proposal introduces some concerns. The choice of Javascript code running on browsers has
some advantages, as is pointed out in the paper, but some important drawbacks. Given that the
motivation of these kinds of distributed models is to solve complex problems, using Javascript doesn\'{}t
appear a right choice. It\'{}s true that is a very commonly used programming language, but in the context of
Web applications, not in high performance ones. Apart from the fact of being an interpreted language
designed for the Web, it is difficult to think on a computer scientist writing a complex math code in
Javascrip. If the authors would have used as a case study a complex optimization problem then they
could have provided numerical data to sustain their claims; however, the selected problem (which should
be formulated in the paper) seems a rather academic one.
\end{quote}

We thank the reviewer for the comment. The only reason why JavaScript
was chosen was because it is the only language that is native to the
browser, allowing to carry out precisely this kind of experiments
where the user is invited to click on an URL and start giving CPU to
it. Although there are many other volunteer frameworks, written in
other languages, that a priori would offer a higher performance, the
key is that they would {\em while they are running}, that is, as soon
as it has been installed, the user has decided to fire it up, and it
does not affect the performance of the rest of his system, which is a % se confundia con el desempeño del todo el sistema
concern in this kind of systems. We have performed speed tests on
JavaScript and other compiled languages resulting that, in fact,
JavaScript uses a JIT compiler that provides a good performance; we
have published these tests as an open access technical report. \cite{2015arXiv151101088M}

JavaScript is probably the most popular language nowadays, and this
has inspired the appearance of many compilers, so that the fitness
function can, in fact, be written in any language and compiled to
JavaScript, as is shown in this list:
\url{https://github.com/jashkenas/coffeescript/wiki/list-of-languages-that-compile-to-js}. This
has also been added to the text.

In a nutshell, what we are saying is that, as is proven in the paper,
a JavaScript application, running in the browser, can gather in
seconds dozens of users. That would be, in practice, impossible with
other kind of native clients, who would have to download and maybe
compile the application, losing many seconds or minutes for the
optimization problem that has to be solved.

These facts, along the explanations, have now been added to the first
paragraph of the {\em Description of the system} section, as well as
to the introduction.

\begin{quote}
The paper organization is not clear. Some comments about this:
- The title "Volunteers in the Clouds: an Architecture for Low Cost and Potentially Massive Distributed
Evolutionary Computation" seems to suggest that the volunteers run in the cloud, but that is not the case:
the server run in the cloud and the volunteers do in the browsers of
common PCs and laptops.
\end{quote}

That is correct. We just used the term {\em cloud} in a relatively informal
sense because they are available as in a cloud for running the
experiment. That is, from the point of view of the person running the
experiment, there is a {\em cloud} out there running your experiments,
which is actually run by volunteers in their browsers. We went to the
original acceptation of ``cloud'' as a ``network'' more than the more
precise and technical sense used today. We have changed the title to
avoid words like {\em potentially}, and we have no strong feelings on
the ``volunteers in the cloud'' part. We like it, but if asked by the
editors, we can eliminate it. 

We have added this explanation to the first paragraph in the
conclusions; we hope this makes our intention clearer, but we can also
eliminate that part of the title if the reviewer thinks it is
necessary. 

\begin{quote}
- The paper abstract does not properly summarize the paper contents. It says that ``That is why in this
paper we present NodIO, a client-server architecture for distributed evolutionary algorithms !'', but there
are two versions of the architecture, as stated later in the conclusions: "In this paper two versions of a
client-server architecture for volunteer and distributed evolutionary !". That second version is neither
commented in the introduction.
\end{quote}

In fact {\sf NodIO} is a framework that can be used to generate
different client-server architectures. This has been clarified in the
abstract and conclusions section. 

\begin{quote}
- According the last paragraph of the introduction, ``Then, a detailed description of the proposed system is
presented in Section III, followed by the experiments and obtained results in Section IV.", but Section IV
does not only contains experimental result but also the full description of the second version of the
architecture.
\end{quote}

You are absolutely right. We have corrected that paragraph to include
the actual contents of the paper. 

\begin{quote}
Summarizing the review, the authors should provide a convincing example showing the advantages of
their proposal. As presented, the paper is a proof of concept of a system that seems difficult to be used
by the researchers needing high computational resources to run an evolutionary algorithm to solve a realworld
problem.
\end{quote}


We have added a new experiment (Section V.A), a more complex and
taxing problem that also uses a web-worker architecture, in order to
prove how this can be 
used in real-life problems. In this case, we have achieved many more
simultaneous users, up to 25 in some minutes and more than 100 in a
single hour. All in all, more than 400 volunteers (identified by
unique IPs) have participated in
the experiment. 

In fact, our architecture {\sf NodIO} is
not an exclusively browser-based one. Its pool-based architecture allows
any other kind of client, including local ones, to be incorporated to
the experiment, with the lightweight overhead of doing asynchronous
HTTP requests, which being local are indeed negligible. 

Our framework, in fact, does not prevent the user to carry out any other kind of
experiments. If there is a very efficient locally run algorithm, it only
needs to be able to do HTTP requests to work alongside a {\em
  volunteer cloud}. What our framework ensures is that all work done
by volunteers can be integrated with local, cloud or other kind of
resources. This explanation has been also added as a paragraph in the
Introduction to the paper.

We would like to thank this reviewer for the helpful comments and
suggestion made. We expect to have addressed them properly, but in any
case are grateful because it has allowed us to improve the quality of
our work. 

\section{Response to Reviewer \#2}

\begin{quote}
Contribution:
This paper describes a client-server architecture for distributed
evolutionary algorithms named NodIO. 
The implementation of the architecture is written entirely in
JavaScript, in order to support persistent, 
asynchronous, distributed evolutionary algorithms running in the browser.
Additionally, the paper presents the results of several experiments
performed to validate the proposal and 
to measure the performance improvement generated by the massive parallel computing.
I think that the contribution is quite relevant, since it provides a
computation platform that is flexible, 
extensible and potentially massive. Personally, I consider it one of the fresher and most promising
proposals in the context of metaheuristic optimization frameworks lately. Hence, our global
recommendation of acceptance with minor changes.
\end{quote}

Thanks for your appreciation.

\begin{quote}
However, the paper still has plenty of room for improvement in three main areas: the experimentation, the
organization and description of the platform, and the presentation and writing style.
Regarding the experimentation, I miss:
-  a section discussing the threats to validity of the experiments

\end{quote}

We have inserted a paragraph at the end of the section that describes
the experimental setup describing what are the challenges that this
kind of voluntary framework must overcome. Another paragraph analyzing
the security from the point of view of the framework used has been
also added. A new paragraph on the security challenges has also been
inserted, third paragraph in this section, to clarify our integral and
pragmatic approach to security, which so far has worked perfectly. 

\begin{quote}
-  an experiment with a more difficult problem (please use the well-known benchmark problems
described in literature).
\end{quote}

An experiment based on the well known Rastrigin's function has been
performed and analyzed. It is now Subsection V.A.

\begin{quote}
-  A comparison in similar conditions of the two implementations of the architecture (the algorithms
used in the experiments are slightly different, but this could lead to dramatic changes in
performance, and consequently, invalidate the comparison performed in the paper). This would
enable a measurement of the actual improvement in performance obtained by the use of web
workers (not that generated due to a different algorithm)
\end{quote}

This has been included as the last subsection of the paper previous to
the conclusions. The new
experiment has a constant population instead of using  population of random size.
We have not found a big influence on the result. 

\begin{quote}
Regarding the organization of the paper, some important details regarding the improved framework
design named is described in the experimentation section. I would reorganize the contents to describe the
improved in detail in section 3, and focus on the experiments, its
results and the discussion in section 4.
\end{quote}

In fact, reorganizing the paper increased the chance of introducing
new issues in this new version. We have preferred to keep it the way
it is, although we thank you for the suggestion. We expect that the
changes made to the text make it clear enough anyway. 

\begin{quote}
Another issue is that some details are described twice, for instance,
the advantages of the use of web 
workers. Fixing this issue can reduce the paper size and improve its
readability.
\end{quote}

We have eliminated duplications in this new version. Thanks for
noticing it.

\begin{quote}
Regarding the presentation:
-  Figures should be readable even in gray-scale, so do not use red and blue to denote different
elements, use a different shade or texture.
-  The axis labels and legends in most of the figures are unreadable, please increase its font size.
-  There are some typos and phrases that need rewriting.
\end{quote}

We have rewritten and revised extensively the paper, and tried to find
a way (and failed) to make it more readable for reviewers. In fact,
they use different shades, so it should mostly work in grayscale. For
the time being and 
during the revision phase, we prefer to keep it that way, but we will
change it to grayscale if it is required for the final version. 
In fact, the labels are not so important, so increasing the font size
would in fact distract the attention from the figure itself, which is
the interesting information we want to convey with the graph. Once
again, we can do it if required for the final version.

\section{Response to Reviewer \#3}

\begin{quote}
1. Contribution: The paper presents the idea of a web browser based distributed evolutionary computing.
the system called NodIO consists of a REST server (coded in Node.js) and clients performing
evolutionary algorithm coded in JavaScript and embedded in a web page. Although the idea is not
entirely new, the authors show how Web Workers (introduced in HTML5) and the mechanism of
automatic restart of computations on the client's side can improve the performance of the system. The
state of the art is comprehensive and provides good introduction into the subject.
\end{quote}

We thank this reviewer for these helpful comments.

\begin{quote}
2. Relevance: In my opinion the system described in the paper is relevant to "Computational Intelligence
Software" special issue. Thanks to both development of Internet technology and continuous increase in
computing power of electronic devices, including mobile devices, the web browser based distributed
computing can be a cheap alternative for grid and high-performance computing systems that require
high capital expenditures and consume a lot of energy. Evolutionary computing system based on the
architecture presented in the paper can be potentially used for solving many different time consuming
problems, however, the authors limited their experiments to a simple ``Trap'' function that can be easily
solved on a desktop machine, what may not be convincing for a reader looking for an effective
optimization tool.
\end{quote}

It is true that that function can be easily solved with any desktop
machine, but we can still do that {\em and} use a volunteer
computation framework, which will add performance to the desktop
machine. Our intention was more to prove what kind of performance can
be expected and how this performance is distributed, although we have
also proved in the last section how the performance achieved by a
volunteer-based computer system can, in fact, be better than a desktop, even
a powerful one. This has also been clarified in the introduction and
conclusions. 

At any rate, we have also performed a new experiment based on the
Rastrigin's function, which in fact cannot be solved in a few minutes
(or seconds, as in the case of Trap) by a desktop system. 


\begin{quote}
3. Correctness: The system works correctly - it is not very complex and the authors provide its source
code (this is a great plus!). Technical description of the system is also clear, however it lacks some
details like parameters of the machine used to determine baselines for the experiments or the format of
messages sent between the server and the clients. The only thing I noticed is that the authors used the
term ``multiple CPUs'' in the description of Web Worker API advantages (page 8) instead of "multi-core
CPUs". As far as I know, contemporary web browsers do not support
multiple CPUs architecture.
\end{quote}

This has been clarified in the new version of the paper, third
paragraph from the beginning of the section that explains the web
worker-based architecture. In fact, most browsers can use multi-core
CPUs running web workers as independent processes in each one of them.
The base system has been now described in the first paragraph of the
section on the experiments, it is a desktop Intel i7-4770. 

\begin{quote}

4. Style: Paper is generally written in a clear way. Statements like
``But fair is fair,'' (page 6), sound a bit colloquially in a scientific
paper and may be omitted. However, my main concern is the readability
of the graphs. General remark - font used for description of axes

\end{quote}

We have eliminated colloquialisms from the text.

\begin{quote}
should be significantly larger. In Fig. 2 the authors can change scale
for axe Y, as the box for the population of 1024 individuals is very
small.  What do the authors mean by ``times''? Time in seconds? I am not
sure if this Figure is necessary at all as the description is
understandable without it. In Fig.4 all graphs are similar and only
the one in the middle is analyzed, so maybe others are not necessary?
\end{quote}

The labels, and indeed the label size, are not too important; the
graph shape is. That is one reason they are grayed out. However, we
have changed as instructed Figure 2, which is more readable now. We do
mean times to solution, shortened for clarity. We have also clarified
that on the caption. We also think that all graphs are needed in Fig
4, since they represent different experiments, and we have added a
sentence to highlight that the {\em tail} appears in all three. 

\begin{quote}
The same is with Fig. 5. What does ``x'' stand for in the description of
axe X? (the same is with Fig. 8).
\end{quote}

$x$ has been changed to {\sf rank}, which is the usual way of
representing Zipf's law, a measure (in this case number of {\tt PUT}s
vs. rank. We have also changed size, color and sigils to represent
each point to make it a bit clearer. 

\begin{quote}

5. Length: As I mentioned above the authors should think of removing some of the unnecessary graphs
in order to improve readability. They admit themselves that it is hard to conclude from some of the
graphs (Fig. 5 and Fig. 8). Nevertheless, overall length of the paper is fine.

\end{quote}

Finally, since the reviewer thinks that length is fine and for the
reasons outlined above, we have decided to keep the graphs and explain
them a bit better.

\begin{quote}
6. Abstract: Abstract is adequate, moreover it puts an accent on the analysis of volunteers' behavior in a
distributed computing system, contrary to the description in the main text of the paper. However, it
lacks the information about the second version of the system called NodIO-W2 based on the Web
Worker architecture.
\end{quote}

We have extended the abstract stressing our main points, that were
first to test the validity and measure the performance of our
framework NodIO and then to use the measures as first steps to a model
of volunteer uses. 


\begin{quote}
Comments to Authors:

1) I like the state of the art which includes comprehensive overview of the most important papers related
to the subject presented in the paper. I also like the description of the system, but I cannot fully agree
with its characteristic provided on page 4. Namely:
 
 - Heterogeneity - it is true that almost all devices can participate in the web browser based
 distributed computing system, providing that a user did not disable Java Script in its browser.
 However if the authors plan to use HTML5 Web Workers only modern web browsers can
 participate in such computing system, and some devices (e.g. based on Android 2.2-4.3 or
 Windows Phone) are also excluded.
 
\end{quote}

That is true, but it makes it anyway the most inclusive system so
far, as we have tested it with smartphones, tablets and computers. In
general, nowadays with rich internet applications disabling JavaScript
is not common, but anyway we do not aim for {\em all} clients, we have
enough with {\em most}. Windows Phone, for instance and maybe
fortunately, is not too common. % ¿no existe Chrome para Windows Phone? De todas formas yo quitaría lo de "and maybe fortunately"...

\begin{quote}
 - Adaptiveness - this, beside safety, is the main drawback of the system. Although it is possible to
 implement evolutionary algorithm in that way that it will automatically adopt to the problem type
 and the environment in which it is computed, the authors do not mention about how real
 adaptiveness of the system can be achieved. The same is with scalability. Only 5 different users
 that permanently participated in the experiments are not enough to assess the scalability of the
 system, what is a crucial parameter for distributed computing.
\end{quote}

We have performed a new experiments in which we have had hundreds of
simultaneous users. In fact, with the experiments already in the
previous version of the papers 5 was a central measure, but there were
peaks of dozens. 
Adaptativity is by design, since it uses any browser and does not need
any special provision for new systems. This has also been explained in
the expanded text.

\begin{quote} 

 - Safety - in my opinion is the biggest concern in such kind of distributed systems. First of all the
 code of evolutionary algorithm is sent to the client as a source code in Java Script, so some
 experienced user may quite simple decode what has to be computed. It can may come into
 possession of sensitive data or/and alter this code in order to disrupt the computations or make
 them worthless. The results send to the server may also be captured and/or altered without any
 problem since the transmission is not secure.

 In my opinion you should at least highlight above issues.
\end{quote}

We have also justified our {\em pragmatic} approach to security
increasing trust by the user, but also monitoring their behavior to
detect it and eventually ban users. So far, this has not happened. 

\begin{quote}
2) Regarding the experiments I am very skeptical about their real value. You chose the ``Trap''
function. in which setting all bits to zero gives local maximum and setting all bits to one gives global
maximum. In the experiments you counted how many times evolutionary algorithm was able to find
global maximum for the problem of size n=40. Initially you have found that if the population in an
evolutionary algorithm is bit enough (1024 individuals) the algorithm returned global maximum
within 3.46 sec. divided by 50 runs - i.e. 0.692 sec. for a single run
(page 4, if I understood it correctly).
\end{quote}

I fact 3.46 is the average for all 50 runs. 
We have emphasized the word average to make that clearer.

\begin{quote}
Thus, what was the point of using distributed computing to solve such simple problem? Why the
authors did not perform their experiments for larger values of n, what could justify distributed problem
solution. You admit that the NodIO system rarely beats a high-performance desktop computer (page
6). Situation is better for the NodIO-W2 using JS Web Workers and automatic restarts, nevertheless,
it is still behind the desktop computer in more than 60% cases (when compared to the second
baseline). I suggest to perform additional computing experiments for some higher value of n in the
``Trap'' function or to choose another type of problem like some NP-hard problem. Otherwise I suggest
to focus the paper on the behavior analysis of volunteers participating in a distributed computing
system, what may be also interesting an valuable for the potential
readers.
\end{quote}

In fact, that was never the point of the paper. We have chosen Trap as
a relatively difficult problem that allows us mainly to test scaling
and measure behavior. In a production environment, a volunteer-only
environment would only be used if there is absolutely no other
resource available; in general, it would be combined with the rest of
the resources available to the experimenter: cloud or local; it would
make no sense to not use them if they are available and in fact, NodIO
allows to combine them seamlessly in a single system. That has been
explained a bit better in the introduction and conclusions
section. Besides, we have added a more difficult problem, the shifted
Rastrigin function (a well known function optimization problem), to make 
measures in a different scenario (one in which the problem is not solved 
in a few seconds). 

\begin{quote}
3) Regarding the graphs I have already put my comments in Style section, but I have one question. In
Fig. 3 in the middle graph (for experiments conducted on 4/24/2015) the is a lot of red dots,
meaning probably that IPs from 16 to 29 did not performed any computations. What was the reason
for that?
\end{quote}

The $x$ axis runs overs number of computers participating in an
experiment; that is, $4$ plots the time taken for all experiments in
which 4 computing nodes participated and the red dot is the average;
it shadows the time in the case there is a single occasion. In the
case you mention, there are no experiments in which there were exactly
17 nodes, for instance. The ``red dots'' indicate that there was a
single experiment in which that many nodes participated. We have
clarified the caption to Figure 3 to make this clearer. 

\begin{quote}
For Fig. 5 I would also avoid comparisons between the NodIO system with the SETI@home of BOINC
systems - the number of participants is completely incomparable and also the type of problems
solved by the systems are of different nature and complexity.
\end{quote}

We have added a sentence clarifying that our intention was simply to
point out that the pattern is similar. We are obviously in a wholly
different league.

\section{Response to Reviewer \#4}

\begin{quote}
This paper presents a very challenging proposal. Namely, authors introduce a novel client-server
architecture for low cost and ``potentially'' massive distributed evolutionary algorithms. The main novelty
turns up from the fact that the architecture is developed in JavaScript.
However, JavaScript is well-known because of its lack of capability to deal with high performance
applications like the ones that are addressed in this paper. Thus, the use of JavaScript makes hard to
believe in the possibility of ``potentially'' massive computation as
sketched by the authors.
\end{quote}

JavaScript is not, in fact, so slow and to prove its speed we have
published a technical report comparing it with other compiled
languages (such as Scala) and scripted languages
\cite{2015arXiv151101088M}. In fact, node.js (used for the benchmarks)
and the JavaScript virtual machine in Chrome (used in Android phones
and Chrome and Chromium browsers) share the same JIT compiler, so
their speeds are virtually the same. In general, as a conclusion of
the report, we see that the real difference between scripted and
compiled languages will vary with the language, but also with the
particular implementation of the algorithm and the size of the problem
or chromosome you are using. Even if the speed for a particular
problem is two or five times that achieved for JavaScript, this
disadvantage is more than offset by the availability of that free
resource in abundance; that is, you will only need that many
volunteers cooperating to get better performance than what you would
get with C or Java. Even so, this NodIO architecture, as highlighted
in the new version of the paper, is pool-based so local sources using
high-speed devices such as GPUs or even local powerful CPUs can be
added as non-volunteer users, since the heterogeneity and simple API
of the system allows that by design. 

\begin{quote}
The paper is well written and organized. State of the art is quite complete. Nevertheless, the experimental
section must be carefully checked and extended in order to fully validate the goodness of the proposed
architecture. At least, authors should show the behavior of the architecture in a real-world problem
demanding high computational performance.
Finally, English must be double-checked in order to correct minor typos such as ``in the sense than[that]''
(in page 2).
\end{quote}

We have extended the experiments section with a new one, based on a
hard version of the Rastrigin's problem. 

\bibliographystyle{IEEEtran}
\bibliography{geneura}

\end{document}
%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% End:
